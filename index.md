---
layout: page
title: "Responsible AI"
doodle: "/doodle.png"
permalink: /
---

Data science capstone domain of inquiry (DSC 180AB A05)

Developed by David Danks, Jeffry Liu, Nandita Rahman, Aritra Nath, Emma Harvey, Meira Gilbert, and Rasmus Nielsen.

---
* TOC
{:toc}

---

# Introduction

The explosive proliferation of research around ethical AI (Artificial Intelligence) and AI trustworthiness during the last decade  reflects a rising societal awareness and desire to address potential and actual harmful impacts and consequences of AI. We introduce students to the socio-technical risks of AI fairness and explainability by examining several high-profile algorithmic discrimination debates that have sparked seminal research in this field. We will discuss the range of alternative definitions, the perspectives they represent, and metrics used to examine AI fairness, and the papers that describe the interesting yet mathematically irreconcilable relationships that interweave them. Concepts around AI-fairness will be translated into real-world applications through classroom debates from the perspectives of different disciplines and stakeholders, and by replicating the analyses from a relevant use case example. Students will conduct an independent fairness and explainability analysis on a mock model using industry recognized toolkits, with an emphasis on understanding how issues that originate in code and math eventually affect real human beings and society as a whole.

In this domain, project proposals will be restricted to the following
areas:
* What does AI trustworthiness and ethics mean for different stakeholders?
* What are the ways to think about whether or not a model is fair?
* What are the risks of ‘black box’ algorithms, and how do we mitigate them? How is AI explainability related to fairness?
* How do inherent fairness problems in AI models affect human beings?  


## Result replication (introduction to topic)
To Be Announced
* [Hindroid](https://www.cse.ust.hk/~yqsong/papers/2017-KDD-HINDROID.pdf)
* [MaMaDroid](https://arxiv.org/pdf/1612.04433.pdf)

The latter-half of Quarter 1 will introduce you to further topics,
like graph embedding techniques and adversarial ML, to inform possible
avenues for further research.

---

# Section Participation

Participation in the weekly discussion section is *mandatory*. Each
week, you are responsible for doing the reading/task assigned in the
[schedule](#schedule). Come to section prepared to ask questions about
and discuss the results of these tasks.


---

# Schedule

|Week|Topic|
|--|--|
|1|[Introduction to Ethical/Trustworthy AI]({{ "weeks/01-Introduction" | absolute_url }})|
|2|[Data: Code Parsing, Malware]({{ "/weeks/02-Data" | absolute_url }})|
|3|[Creating Graphs from Code; What is Malware?]({{ "/weeks/03-Android-Graphs" | absolute_url }})|
|4|[Graph Invariants as Measurements]({{ "/weeks/04-Graph-Features" | absolute_url }})|
|5|[Building a Baseline Model]({{ "/weeks/05-Baseline-Model" | absolute_url }})|
|6|[Evalulating the HinDroid Result]({{ "/weeks/06-Hindroid" | absolute_url }})|
|7|[Graph Embedding I: node2vec]({{ "/weeks/07-Graph-Embeddings-I" | absolute_url }})|
|8|[Graph Embedding II: metapath2vec]({{ "/weeks/08-Graph-Embeddings-II" | absolute_url }})|
|9|[Production and Adversarial ML]({{ "/weeks/09-Adversarial-ML" | absolute_url }})|
|10|Present Proposals|

---

# Office Hours

Fridays 9-11AM



