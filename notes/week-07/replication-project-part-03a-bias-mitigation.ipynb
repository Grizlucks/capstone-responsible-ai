{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9395c475",
   "metadata": {},
   "source": [
    "## DSC 180AB Data Science Capstone\n",
    "### Replication Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49e865",
   "metadata": {},
   "source": [
    "Team Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7799d7d3-7572-4e08-9e3a-812ba39befda",
   "metadata": {},
   "source": [
    "The notebook demonstrates how the AIF 360 toolkit can be used to detect and reduce bias when learning classifiers using a variety of fairness metrics and algorithms . It also demonstrates how explanations can be generated for predictions made by models learnt with the toolkit using LIME.\n",
    "\n",
    "* Classifiers are built using Logistic Regression as well as Random Forests.\n",
    "* Bias detection is demonstrated using several metrics, including disparate impact, average odds difference, statistical parity difference, equal opportunity difference, and Theil index.\n",
    "* Bias alleviation is explored via a variety of methods, including reweighing (pre-processing algorithm), prejudice remover (in-processing algorithm), and disparate impact remover (pre-processing technique).\n",
    "* Data from the [Medical Expenditure Panel Survey](https://meps.ahrq.gov/mepsweb/) is used in this tutorial.\n",
    "\n",
    "\n",
    "The Medical Expenditure Panel Survey (MEPS) provides nationally representative estimates of health expenditure, utilization, payment sources, health status, and health insurance coverage among the noninstitutionalized U.S. population. These government-produced data sets examine how people use the US healthcare system.\n",
    "\n",
    "MEPS is administered by the Agency for Healthcare Research and Quality (AHRQ) and is divided into three components: \n",
    "* Household\n",
    "* Insurance/Employer, and \n",
    "* Medical Provider. \n",
    "\n",
    "These components provide comprehensive national estimates of health care use and payment by individuals, families, and any other demographic group of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebad3269",
   "metadata": {},
   "source": [
    "### [1.](#Table-of-Contents) Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c682f615",
   "metadata": {},
   "source": [
    "The [AI Fairness 360 toolkit](https://github.com/Trusted-AI/AIF360) is an extensible open-source library containing techniques developed by the research community to help detect and mitigate bias in machine learning models throughout the AI application lifecycle. AI Fairness 360 package is available in both Python and R. Documentation is available [here](https://aif360.readthedocs.io/en/v0.2.3/index.html)\n",
    "\n",
    "The AI Fairness 360 package includes: \n",
    "- a comprehensive set of metrics for datasets and models to test for biases,\n",
    "- explanations for these metrics, and\n",
    "- algorithms to mitigate bias in datasets and models\n",
    "It is designed to translate algorithmic research from the lab into the actual practice of domains as wide-ranging as finance, human capital management, healthcare, and education"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523227a6-425b-4dba-bb8a-81ea10e59102",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.1 Use Case\n",
    "\n",
    "**In order to demonstrate how AIF360 can be used to detect and mitigate bias in classfier models, we adopt the following use case:**\n",
    "\n",
    "* Data scientist develops a 'fair' healthcare utilization scoring model with respect to defined protected classes. Fairness may be dictated by legal or government regulations, such as a requirement that additional care decisions be not predicated on factors such as race of the patient.\n",
    "* Developer takes the model AND performance characteristics / specs of the model (e.g. accuracy, fairness tests, etc. basically the model factsheet) and deploys the model in an enterprise app that prioritizes cases for care management.\n",
    "* The app is put into production and starts scoring people and making recommendations. \n",
    "* Explanations are generated for each recommendation\n",
    "* Both recommendations and associated explanations are given to nurses as a part of the care management process. The nurses can evaluate the recommendations for quality and correctness and provide feedback.\n",
    "* Nurse feedback as well as analysis of usage data with respect to specs of the model w.r.t accuracy and fairness is communicated to AI Ops specialist and LOB user periodically.\n",
    "* When significant drift in model specs relative to the model factsheet is observed, the model is sent back for retraining."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b3fccd-dada-42d4-a408-42582b8d060f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 1.2 Data\n",
    "Released as an ASCII file (with related SAS, SPSS, and STATA programming statements) and a SAS transport dataset, this public use file provides information collected on a nationally representative sample of the civilian noninstitutionalized population of the United States for calendar year 2015. This file consists of MEPS survey data obtained in Rounds 3, 4, and 5 of Panel 19 and Rounds 1, 2, and 3 of Panel 20 (i.e., the rounds for the MEPS panels covering calendar year 2015) and consolidates all of the final 2015 person-level variables onto one file. This file contains the following variables previously released on HC-174: survey administration, language of interview variable, demographics, parent identifiers, health status, disability days variables, access to care, employment, quality of care, patient satisfaction, health insurance, and use variables. The HC-181 file also includes these variables: income variables and expenditure variables.\n",
    "\n",
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcd0b66-89d3-4e62-a3af-1b62b3dbaf27",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 1.3 Methodology \n",
    "\n",
    "For each dataset, the sensitive attribute is 'RACE' constructed as follows: 'Whites' (privileged class) defined by the features RACEV2X = 1 (White) and HISPANX = 2 (non Hispanic); 'Non-Whites' that included everyone else.  \n",
    "\n",
    "* Along with race as the sensitive feature, other features used for modeling include demographics  (such as age, gender, active duty status), physical/mental health assessments, diagnosis codes (such as history of diagnosis of cancer, or diabetes), and limitations (such as cognitive or hearing or vision limitation).\n",
    "* To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have 'high' utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset.\n",
    "* To simulate the scenario, each dataset is split into 3 parts: a train, a validation, and a test/deployment part.\n",
    "\n",
    "**We assume that the model is initially built and tuned using the 2015 Panel 19 train/test data**\n",
    "* It is then put into practice and used to score people to identify potential candidates for care management. \n",
    "* Initial deployment is simulated to 2015 Panel 20 deployment data. \n",
    "* To show change in performance and/or fairness over time, the 2016 Panel 21 deployment data is used. \n",
    "* Finally, if drift is observed, the 2015 train/validation data is used to learn a new model and evaluated again on the 2016 deployment data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913a44da",
   "metadata": {},
   "source": [
    "### 1.4 Insert writeup of overall replication project goals and big picture thinking (2-3 paragraphs).  \n",
    "* Why do we care about this? \n",
    "* What would the benefit of predicting utilization be? \n",
    "* What might occur if there are errors?\n",
    "* Who are the affected parties and stakeholders?\n",
    "* Other thoughts?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7569b-9388-4939-9422-6d134dbc0303",
   "metadata": {},
   "source": [
    "**Write up here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f776c5-8ed6-49c3-9f12-f2afed0605d4",
   "metadata": {},
   "source": [
    "---\n",
    "End of Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1413d0",
   "metadata": {},
   "source": [
    "### [2.](#Table-of-Contents) Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c4a57f-abcf-47c6-961e-baec728e930a",
   "metadata": {},
   "source": [
    "The specific data used is the [2015 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) as well as the [2016 Full Year Consolidated Data File](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-192).\n",
    "\n",
    "* The 2015 file contains data from rounds 3,4,5 of panel 19 (2014) and rounds 1,2,3 of panel 20 (2015). \n",
    "* The 2016 file contains data from rounds 3,4,5 of panel 20 (2015) and rounds 1,2,3 of panel 21 (2016).\n",
    "\n",
    "In this example, three datasets were constructed: one from panel 19, round 5 (used for learning models), one from panel 20, round 3 (used for deployment/testing of model - steps); the other from panel 21, round 3 (used for re-training and deployment/testing of updated model).\n",
    "\n",
    "See the corresponding [Codebook](https://meps.ahrq.gov/mepsweb/data_stats/download_data_files_detail.jsp?cboPufNumber=HC-181) for information on variables.\n",
    "\n",
    "##### Key MEPS dataset features include:\n",
    "* **Utilization**: To measure utilization, a composite feature, 'UTILIZATION', was created to measure the total number of trips requiring some sort of medical care by summing up the following features: OBTOTV15(16), the number of office based visits;  OPTOTV15(16), the number of outpatient visits; ERTOT15(16), the number of ER visits;  IPNGTD15(16), the number of inpatient nights, and  + HHTOTD16, the number of home health visits.\n",
    "* The model classification task is to predict whether a person would have **'high'** utilization (defined as UTILIZATION >= 10, roughly the average utilization for the considered population). High utilization respondents constituted around 17% of each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7368b94-7451-4cf1-8a66-229d2a07907d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "#### 2.0 Pre-processing Scripts (for each Panel)\n",
    "\n",
    "There is currently minimal EDA for this tutorial within IBM AIF360 Medical Expenditure Tutorial. Therefore, we have adapted  utility scripts from IBM AIF360 Tutorial for ease of understanding for how datasets were pre-processed. These will be used primarily for EDA purposes. We will utilize IBM's tutorial for the remainder of the project. We have utilized Pandas for this portion of the project. \n",
    "\n",
    "**Note:** these pre-processing script below are run for each data file, and then filtered for each panel. This was done in order to match subsequent portions of the tutorial, and how train/test/validation datasets were split."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b833fd",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### 2.1 Get and Load Dataset, Apply Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd36982c-27bb-4159-9d99-1730c1ca8b6c",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Before Proceeding Ensure You Have:**\n",
    "* Forked the AIF360 R=repository and cloned locally to your disk or virtual machine\n",
    "* Downloaded the `h181.csv` and `h192.csv` data files uploaded [here](https://www.kaggle.com/datasets/nanrahman/mepsdata)\n",
    "* Place the `h181.csv` and `h192.csv` in a folder you can access (we placed it in `../aif360/data/raw/meps/` of our forked AIF360 repository)\n",
    "* For EDA we only focus on `h181.csv` "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90379749-ae30-4908-b400-400254239ecd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### REPLACE THIS SECTION WITH REPLICATION PART 02 - EDA ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447543a0-cc93-4f46-bcac-c5c11e2de8ee",
   "metadata": {
    "tags": []
   },
   "source": [
    "### REPLACE THIS SECTION WITH REPLICATION PART 03 - MODEL DEVELOPMENT AND FAIRNESS EVALUATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef7f4e6-b2f0-4c7c-ab1f-9094a6339865",
   "metadata": {
    "tags": []
   },
   "source": [
    "-----\n",
    "# Start of Replication Part 03 -  Bias Mitigation Techniques\n",
    "\n",
    "## There are **two** components to `Replication Project Part #03`\n",
    "\n",
    "### Part 1. Run the full tutorial example. Within AIF360's Repository it can be found under: `AIF360`/`Examples`/tutorial_medical_expenditure.ipynb\n",
    "\n",
    "#### BEFORE YOU BEGIN MAKE SURE THAT:\n",
    "* A reminder, you will need to fork [AIF360's repository](https://github.com/Trusted-AI/AIF360) into your own GitHub and access the notebook locally or via your method of choice\n",
    "* AIF360's Repository can be found under: `AIF360`/`Examples`/tutorial_medical_expenditure.ipynb\n",
    "* Ensure you have your `aif360` environment turned and activated using a miniconda prompt\n",
    "* Use Jupyter Labs\n",
    "* Refer to [Week 03](https://nanrahman.github.io/capstone-responsible-ai/weeks/03-Replication-Part-00/) content on the course Website to access the `Quickstart Guide`\n",
    "\n",
    "#### FOR THE DATA\n",
    "* Downloade the `h181.csv` and `h192.csv` data files uploaded [here](https://www.kaggle.com/datasets/nanrahman/mepsdata)\n",
    "* Place the `h181.csv` and `h192.csv` ino `../aif360/data/raw/meps/` of your forked AIF360 repository\n",
    "\n",
    "### Part 2. Training models WITH de-biasing, trying out another type of de-biasing method\n",
    "\n",
    "*Below is a list of additional notebooks that demonstrate the use of AIF360*\n",
    "\n",
    "* NEW: [sklearn/demo_new_features.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/sklearn/demo_new_features.ipynb): highlights the features of the new scikit-learn-compatible API\n",
    "* [demo_optim_data_preproc.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_optim_data_preproc.ipynb): demonstrates a generalization of the credit scoring tutorial that shows the full machine learning workflow for the optimized data pre-processing algorithm for bias mitigation on several datasets\n",
    "* [demo_adversarial_debiasing.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_adversarial_debiasing.ipynb): demonstrates the use of the adversarial debiasing in-processing algorithm to learn a fair classifier\n",
    "* [demo_calibrated_eqodds_postprocessing.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_calibrated_eqodds_postprocessing.ipynb): demonstrates the use of an odds-equalizing post-processing algorithm for bias mitigiation\n",
    "* [demo_disparate_impact_remover.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_disparate_impact_remover.ipynb): demonstrates the use of a disparate impact remover pre-processing algorithm for bias mitigiation\n",
    "* [demo_lfr.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_lfr.ipynb): demonstrates the use of the learning fair representations algorithm for bias mitigation\n",
    "* [demo_lime.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_lime.ipynb): demonstrates how LIME - Local Interpretable Model-Agnostic Explanations - can be used with models learned with the AIF 360 toolkit to generate explanations for model predictions\n",
    "* [demo_reject_option_classification.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_reject_option_classification.ipynb): demonstrates the use of the Reject Option Classification (ROC) post-processing algorithm for bias mitigation\n",
    "* [demo_reweighing_preproc.ipynb](https://github.com/Trusted-AI/AIF360/blob/master/examples/demo_reweighing_preproc.ipynb): demonstrates the use of a reweighing pre-processing algorithm for bias mitigation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed5dfc-0e72-47b7-ba81-a36abe98b40c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b3e294",
   "metadata": {},
   "source": [
    "## [5.](#Table-of-Contents) Bias Mitigation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d267d787-ca80-486a-a183-703e54c58ab9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [5A.](#Table-of-Contents) Bias mitigation using pre-processing technique, Reweighing - AIF360 Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956822fc-281e-4f7e-ad3c-ebdacab682c1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### [5B.](#Table-of-Contents) Prejudice Remover (in-processing bias mitigation) -  AIF360 Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff534f6-bbf7-4e77-ba99-15e24c43e784",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [5C.](#Table-of-Contents) Bias mitigation using a technique of your own\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
