---
layout: week
title: Replication Project Part 03: Bias Mitigation
permalink: /weeks/07-Bias-Mitigation/
doodle: /images/bias_in_labels.png
---

# Replication Project Part 03: Bias Mitigation

## Class Coverage
* Mitigating fairness issues in AI through pre-, in-, and post-processing
* Re-learning and re-deploying models. 

## Pre-Class Readings
Please read the following:
* [Model Cards for Model Reporting (Mitchell et al.)](https://arxiv.org/abs/1810.03993)
* [Fairness Through Awareness (Dwork et al.)](https://arxiv.org/abs/1104.3913)
* [Demo: Explaining model behavior using LIME](https://nbviewer.org/github/Trusted-AI/AIF360/blob/master/examples/demo_lime.ipynb)

## Participation Questions 
_Submit to Gradescope by 10AM PT on Wednesday, November 10th_
* In what situations do you think “fairness through awareness” are most appropriate? Are there any situations where “fairness through unawareness” is necessary instead?
* Describe a situation in which a pre-, in-, or post-processing technique might be appropriate for mitigating model bias, and explain what technique you would use.

## This Week's Slides
*Coming Soon*

## Assigned for Week 08
*Coming Soon*

## Office Hours for Replication Project
* Mondays from 1-2pm PT (4-5pm ET)
* Nandita hosting virtually ([Zoom link](https://github.com/nanrahman/capstone-responsible-ai/blob/85fa88b88441f0dcd04e9fa84519ab0aa7090df2/notes/week-04/replication-office-hour-zoom-info.md))

---
[Go back to Home](https://nanrahman.github.io/capstone-responsible-ai/)
---
